{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2f5f09",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf74ab1",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e00d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8788151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Naren Kumar\\Downloads\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf318865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1f70383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"6364be94-0752-4905-a715-a753bfdea1ce\")>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find web element for search bar using class name\n",
    "search_job = driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1908bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78293a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"19730911-55d4-4f33-a174-9c00c2cfdbee\")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding web element for search location bar using relative Xpath \n",
    "search_loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "search_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fccce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for job locatin bar\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f30018d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Current Version:- 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "  \n",
    "  \n",
    "print(\"User Current Version:-\", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2444d7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"eaf7f1cb-7de7-4218-aee7-5eef53ee34f5\")>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clicking using web absolute xpath function \n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b41d480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668cbfe",
   "metadata": {},
   "source": [
    "# Extracting Job Titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36c78601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all the web element having job titles\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "len(title_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7084900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "job_location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1c556a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's job title: \n",
      " ['Data Analyst I', 'Data Science / Data Engineer / Business Analyst / Full Stack Developer', 'Sr.Business Data Analyst', 'Senior Data Analyst', 'Sr Data Analyst', 'Data Analyst - IIM/ISB/MDI/FMS/SP Jain', 'Data Analyst / Business analyst - US MNC (analytics)', 'Business Analyst/Data Analyst', 'Junior Data Analyst', 'Senior Data Analysis Analyst']\n"
     ]
    }
   ],
   "source": [
    "for i in title_tags:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "job_title = job_title[0:10]\n",
    "\n",
    "print(\"Below are the top 10 job data's job title: \\n\", job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d88cd43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"1ee7c7f3-669e-4576-aef6-c3f82ae51ed5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"a75b2139-f69c-4d74-817f-b837f2dbe573\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"bea0e014-283b-47b7-a0ec-3aec0a34cabc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"f51975a3-ca0a-4ebb-b9f5-8361242efad6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"a48c327f-2fff-404d-8434-3f694655f17d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"69ba7d51-ad80-4684-9f73-8bd16424c96a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"d7d3b8e3-f8e9-4114-b0c3-0d5d71e60e5d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"6833a4cc-a5f0-4243-9aca-86766456655e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"0e388532-508a-4a3b-86cf-cba9b25f57b9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"f22d06f5-1cad-404c-8a65-a2db82e235f7\")>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having company name\n",
    "\n",
    "company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49ccb1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's : \n",
      " ['Affine', 'Everest Fleet Pvt. Ltd.', 'Yespired', 'Thomson Reuters', 'KrazyBee', 'Accenture', 'Talent Placers', 'RGBSI', 'Botree Software', 'Jobs Accuracy']\n"
     ]
    }
   ],
   "source": [
    "# extract the job title text iteratively from these tags one by one\n",
    "\n",
    "for i in company_tag:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "company_name = company_name[10:20]\n",
    "print(\"Below are the top 10 job data's : \\n\", company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03ac886b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"804334f2-7081-4b49-8c02-d5c724dfe614\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"cfe79c68-394b-4599-be76-f3c871765cc2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"1f5394e3-c527-4018-8611-32fb932b4b48\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"ab4182e2-8206-42af-827a-f3d4e093fe21\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"31dd17ea-4b79-495f-923e-de893e68965c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"95a70ca0-3ab9-4eeb-8181-5cd3a189fc8a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"2ce8f57f-ea4d-484f-9b8a-7bb5bba0df33\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"e6f9b650-d3d7-4fa3-87f5-012fe6c23fe4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"c92f64cf-21aa-41d7-b93a-359edd362cad\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"b6627354-9807-4b9d-86c7-c8a5d67445bb\")>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-experience\n",
    "\n",
    "exp_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "exp_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "020e6e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's job title: \n",
      " ['5-10', '0-3', '6-11', '3-4', '5-8', '4-9', '2-7', '3-5', '1-6', '7-12']\n"
     ]
    }
   ],
   "source": [
    "# extract the job experience text iteratively from these tags one by one\n",
    "\n",
    "for i in exp_tag: \n",
    "    experience_required.append(i.text.split(\" \")[0])\n",
    "experience_required= experience_required[0:10]\n",
    "print(\"Below are the top 10 job data's job title: \\n\", experience_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94a47a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"f513dcfe-aa64-4998-a27a-303d73a796f8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"1fcaf82b-edfa-4b9e-b843-bcab30424c49\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"14e52ab5-1ee6-42f7-90fd-277e53f063c3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"73214353-06e8-46e0-88b1-d2ab5f89a0ed\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"0da33c94-9a78-4bcd-b2bb-88a044c6a7db\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"9e2f5dbd-b96c-4bd6-b3c4-4565abdcf18b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"cfa7daba-79d3-4341-9c43-e9bfce960968\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"dab7b232-af53-46e8-9d57-21bb3aec537a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"0dbbdc89-b86c-46d3-b03d-635cb047ba6c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"a90006c5d8f84a1223b2ade3174783b0\", element=\"d0524f26-6f8c-4451-8e79-6aea84dc80f2\")>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-location \n",
    "\n",
    "location_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f08c7cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's company location \n",
      " ['Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru, karnataka\\n(WFH during Covid)', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi / NCR\\n(WFH during Covid)', 'Bangalore/Bengaluru, Hyderabad/Secunderabad, Delhi / NCR', 'Bangalore/Bengaluru, New Delhi', 'Bangalore/Bengaluru, Pune, Chennai']\n"
     ]
    }
   ],
   "source": [
    "for i in location_tag:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "job_location = job_location[0:10]\n",
    "print(\"Below are the top 10 job data's company location \\n\", job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c843408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Affine</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science / Data Engineer / Business Analys...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Everest Fleet Pvt. Ltd.</td>\n",
       "      <td>0-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "      <td>Yespired</td>\n",
       "      <td>6-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>3-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>5-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - IIM/ISB/MDI/FMS/SP Jain</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst / Business analyst - US MNC (anal...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...</td>\n",
       "      <td>Talent Placers</td>\n",
       "      <td>2-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Analyst/Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, D...</td>\n",
       "      <td>RGBSI</td>\n",
       "      <td>3-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi</td>\n",
       "      <td>Botree Software</td>\n",
       "      <td>1-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analysis Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Jobs Accuracy</td>\n",
       "      <td>7-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Analyst I   \n",
       "1  Data Science / Data Engineer / Business Analys...   \n",
       "2                           Sr.Business Data Analyst   \n",
       "3                                Senior Data Analyst   \n",
       "4                                    Sr Data Analyst   \n",
       "5             Data Analyst - IIM/ISB/MDI/FMS/SP Jain   \n",
       "6  Data Analyst / Business analyst - US MNC (anal...   \n",
       "7                      Business Analyst/Data Analyst   \n",
       "8                                Junior Data Analyst   \n",
       "9                       Senior Data Analysis Analyst   \n",
       "\n",
       "                                            Location             Company_Name  \\\n",
       "0                                Bangalore/Bengaluru                   Affine   \n",
       "1                                Bangalore/Bengaluru  Everest Fleet Pvt. Ltd.   \n",
       "2  Bangalore/Bengaluru, karnataka\\n(WFH during Co...                 Yespired   \n",
       "3                                Bangalore/Bengaluru          Thomson Reuters   \n",
       "4                                Bangalore/Bengaluru                 KrazyBee   \n",
       "5                                Bangalore/Bengaluru                Accenture   \n",
       "6  Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...           Talent Placers   \n",
       "7  Bangalore/Bengaluru, Hyderabad/Secunderabad, D...                    RGBSI   \n",
       "8                     Bangalore/Bengaluru, New Delhi          Botree Software   \n",
       "9                 Bangalore/Bengaluru, Pune, Chennai            Jobs Accuracy   \n",
       "\n",
       "  Experience  \n",
       "0       5-10  \n",
       "1        0-3  \n",
       "2       6-11  \n",
       "3        3-4  \n",
       "4        5-8  \n",
       "5        4-9  \n",
       "6        2-7  \n",
       "7        3-5  \n",
       "8        1-6  \n",
       "9       7-12  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making DataFrame of the top 10 job details from the \"wwww.naukri.com\"\n",
    "\n",
    "naukri_analytics = pd.DataFrame({'Title':job_title, \n",
    "                       'Location': job_location,\n",
    "                       'Company_Name':company_name, \n",
    "                       'Experience':experience_required,                        \n",
    "                       })\n",
    "naukri_analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050bc522",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps: ##1. First get the webpage https://www.naukri.com/ 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field. 3. Then click the search button. 4. Then scrape the data for the first 10 jobs results you get. 5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "257f4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Naren Kumar\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d89f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_location=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_location.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e7d5ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"e589cd32-f96c-43d6-8781-0a0cc4d085f7\")>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clicking using web absolute xpath function \n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "123d91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2bf3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05269851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"e8c68cf0-9234-4ce4-9a30-21e5040d0b70\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"19ce4c50-c413-4fd0-ac86-4d7bbc3ea04e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"5049cb29-9182-4c60-82f4-009f54d561b1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"a9d6f4d3-8421-4bb2-9377-516178c3fc7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"f0929c37-d7d0-4621-adb7-fcf6104f3b7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"9a1f7d99-8dbe-410b-b0a7-afa6bc8db637\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"5c165d0d-2e04-4a25-86e0-74544f0bd2b7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"a3911c6a-60e6-446e-bd62-bea9748c3f42\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"c54a4bef-487d-4f36-a572-88bf34935ec6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"d21c3189-525e-4777-b9f8-839e0b52a682\")>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-titles\n",
    "\n",
    "title_tag = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73f242db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's job title: \n",
      " ['Urgent Job Opening For AI Practitioner - Data Science at Wipro Holmes', 'Hiring For Senior Data Scientist', 'Senior Data Scientist', 'Dataiku Consultant', 'Research and Development -AI/ML -(PhD )', 'Opportunity For Data Scientist - Female Candidates ONLY', 'Senior Data Science Engineer', 'Data Science - Engineering Manager', 'Data Scientist', 'Data & Analytics Tech - Informatica Cloud- Senior Associate']\n"
     ]
    }
   ],
   "source": [
    "# extract the job title text iteratively from these tags one by one\n",
    "\n",
    "for i in title_tag:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "job_title = job_title[0:10]\n",
    "\n",
    "print(\"Below are the top 10 job data's job title: \\n\", job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29075b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"14a9cdd9-acf0-46d8-9694-586cecc0d372\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"6ecb4788-402e-4e63-a4e2-624327b869d4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"2cb9f984-03e0-437e-8109-f2a4a9725787\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"cd28f3fe-e2ca-4b5c-a076-301fdfbb1e03\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"90f109ac-7439-4748-b607-eb97a37e2cfd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"06c753a9-5650-4ced-9a06-8d210261473c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"6b8e77c7-0dfa-49c5-89a3-22089d3ee1a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"13f2377f-ae79-452c-af05-b55703df1818\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"bbc66288-1d0b-4285-8047-a7fc7e8dc409\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"4f9d4e6b-1efc-4175-92eb-f35a951b3931\")>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-location \n",
    "\n",
    "location_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02858a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's company location \n",
      " ['Kochi/Cochin, New Delhi, Bangalore/Bengaluru, Coimbatore, Chennai, Pune, Mumbai, Hyderabad', 'Pune, Bangalore/Bengaluru', 'Mumbai, Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru, REMOTE', 'Pune, Chennai, Bangalore/Bengaluru', 'Noida, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Delhi / NCR', 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)', 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)', 'Noida, Mumbai, Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru']\n"
     ]
    }
   ],
   "source": [
    "# extract the job location text iteratively from these tags one by one\n",
    "\n",
    "for i in location_tag:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "job_location = job_location[0:10]\n",
    "print(\"Below are the top 10 job data's company location \\n\", job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89bae31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"36942d69-7c64-4406-b17c-93d9d7b60ee5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"c8b63f5a-5124-45ba-901f-2ad4f369f6fd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"e4ba62f8-1dff-4f7f-8280-e0342e303b46\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"e657c541-fa7c-46d5-ab6d-c1c7910cad1a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"3a0b12f9-68d9-486b-b91b-13c0ce2202c5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"3ae7e738-0958-4541-87cc-77b6c01b32bd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"a2674480-af80-4899-b87f-d7bc3c22dd9a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"1a8c1359-8a8a-4edb-957e-d6fbe8a98830\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"5d8598fa-0092-4eb4-83e1-b995856a47ad\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6ef771bf5cc00f0d740a86bf8b6f5e8e\", element=\"dd3b8b0e-d6e8-4d69-b719-ec903137e47b\")>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having company name\n",
    "\n",
    "company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b7194fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's : \n",
      " ['Wipro', 'TATA CONSULTANCY SERVICES (TCS)', 'Spiceworks', 'Wipro', 'EXL', 'PayU', 'Fractal Analytics', 'Paytm', 'Applied Materials', 'PwC']\n"
     ]
    }
   ],
   "source": [
    "# extract the company name text iteratively from these tags one by one\n",
    "\n",
    "for i in company_tag:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "company_name = company_name[0:10]\n",
    "print(\"Below are the top 10 job data's : \\n\", company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c189c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Kochi/Cochin, New Delhi, Bangalore/Bengaluru, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Bangalor...</td>\n",
       "      <td>Spiceworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opportunity For Data Scientist - Female Candid...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Noida, Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "1                   Hiring For Senior Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                                 Dataiku Consultant   \n",
       "4            Research and Development -AI/ML -(PhD )   \n",
       "5  Opportunity For Data Scientist - Female Candid...   \n",
       "6                       Senior Data Science Engineer   \n",
       "7                 Data Science - Engineering Manager   \n",
       "8                                     Data Scientist   \n",
       "9  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kochi/Cochin, New Delhi, Bangalore/Bengaluru, ...   \n",
       "1                          Pune, Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Pune, Bangalor...   \n",
       "3                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "4  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "5  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "6  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "7                 Noida, Mumbai, Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                      Company_Name  \n",
       "0                            Wipro  \n",
       "1  TATA CONSULTANCY SERVICES (TCS)  \n",
       "2                       Spiceworks  \n",
       "3                            Wipro  \n",
       "4                              EXL  \n",
       "5                             PayU  \n",
       "6                Fractal Analytics  \n",
       "7                            Paytm  \n",
       "8                Applied Materials  \n",
       "9                              PwC  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making DataFrame of the top 10 job details from the \"wwww.naukri.com\"\n",
    "\n",
    "naukri_scientist = pd.DataFrame({'Title':job_title, \n",
    "                       'Location': job_location,\n",
    "                       'Company_Name':company_name,                                   \n",
    "                       })\n",
    "naukri_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcda697",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n",
    "\n",
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "Then click the search button.\n",
    "Then apply the location filter and salary filter by checking the respective boxes\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data. Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "764ac021",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fd57dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “Data Scientist” in “Skill, Designations, Companies” field.\n",
    "search_job = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "756e52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "834bb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the location filter \"Delhi-NCR\" and salary \"3-6 lakh\" filter by checking the respective boxes\n",
    "\n",
    "loc_clk=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft']\")\n",
    "for i in loc_clk:\n",
    "    if i.text == 'Delhi / NCR':   \n",
    "        i.click() # Checking the checkbox to apply filter on the location\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "524bff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying salary filter\n",
    "sal_clk=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft']\")\n",
    "for i in sal_clk:\n",
    "    if i.text == '3-6 Lakhs':   \n",
    "        i.click() # Checking the checkbox to apply filter on the salary\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20c8d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508&ctcFilter=3to6\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37d1cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "job_location=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "acebf60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"88dad9ab-c3d0-4e44-845b-927193df2ee7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"da64ff25-7b65-4fab-aed4-2cf6f4e0cd12\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"2f3f77d1-5b6b-40d8-a96c-d46e955158fc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"25421672-00ce-4c90-8b6d-ef7704a5cfbd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"5c90fb7d-51ab-4620-bc80-d8d9900c5a91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"25a6d32d-639d-4d1f-80bb-d175dd468bcf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"871ef66e-2258-43e2-a8f1-adac77e47fe9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"5ccc762f-93f8-446f-b69b-33028a28ac57\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"987abf8e-2264-4636-ab8f-140dfe178af1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"0b323529-ccff-4abe-a85f-7b1766363710\")>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-titles\n",
    "\n",
    "title_tag = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "252c96e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST of top 10 job data's job title: \n",
      " ['DigitalBCG GAMMA Data Scientist', 'Senior Associate - Data Science', 'Data Scientist - Noida/Bangalore', 'Data Scientist - Engine Algorithm', 'Data Scientist For Healthcare Product team', 'Data Scientist For Healthcare Product team', 'Data Scientist - MIND Infotech', 'Data Scientist', 'Data Science Associate', 'Knowledge/Data Scientist']\n"
     ]
    }
   ],
   "source": [
    "# extract the job title text iteratively from these tags one by one\n",
    "\n",
    "for i in title_tag:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "job_title = job_title[0:10]\n",
    "\n",
    "print(\"LIST of top 10 job data's job title: \\n\", job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf562cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"fe076ea8-0740-4991-acf6-87311a206bd0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"a7ae5fa3-4855-4322-a829-159b5c6d16ff\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"a5eb16a6-e65b-40f5-a799-dc3d884c98a6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"60ea5833-ef06-4c94-aea6-acfee9b7723f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"1d1bcff4-e4f5-414f-bdb3-f364028f0572\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"ad3f70ff-20ab-4b62-b314-effe8da6b343\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"3ccc2ab3-b48f-4171-8f9c-8a3d66df2d33\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"4cad7f23-da6e-4223-abd7-8036ad520719\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"f1a64655-4132-4b58-8fe3-8c44d094c959\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"ddf80f69-5456-40f9-952f-b480c7deba73\")>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-location \n",
    "\n",
    "location_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea7a1fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF top 10 job data's company location \n",
      " ['New Delhi, Bangalore/Bengaluru', 'Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru', 'Noida, Bangalore/Bengaluru', 'Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secunderabad, Lucknow, Chennai, Ahmedabad, Bangalore/Bengaluru', 'Delhi / NCR, Chennai, Bangalore/Bengaluru', 'Delhi / NCR, Chennai, Bangalore/Bengaluru', 'Noida', 'Delhi / NCR, Bangalore/Bengaluru, Mumbai (All Areas)\\n(WFH during Covid)', 'Delhi / NCR(Vaishali)', 'Delhi / NCR']\n"
     ]
    }
   ],
   "source": [
    "# extract the job location text iteratively from these tags one by one\n",
    "\n",
    "for i in location_tag:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "job_location = job_location[0:10]\n",
    "print(\"LIST OF top 10 job data's company location \\n\", job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4556ada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"4ed85c62-0ad7-4e7b-ad50-e8e766046962\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"2a25a1a2-13c7-4168-87ac-b5fe7f97d861\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"6939bb01-65f1-4946-8e82-a102bc88805d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"e22b26c5-5c13-43ec-8ecd-cb957913fb34\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"fa752dee-a64a-4f9c-88a9-42921ea33191\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"7169b6e4-951f-43dc-bd52-f462ee0eff98\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"753edc26-c321-4c5e-9d53-5eef70557753\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"305337e8-b7b9-498f-b4ea-16c6fa21b33d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"3d894001-35ca-4a32-b7d3-d5e88b39a2ba\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"b599bc83-8fb9-4fc9-8b6f-18303cbd3329\")>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having company name\n",
    "\n",
    "company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03aa6513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST top 10 job data's : \n",
      " ['Boston Consulting Group', 'Black Turtle', 'EXL', 'Primo Hiring', 'SECUREKLOUD TECHNOLOGIES', 'SECUREKLOUD TECHNOLOGIES', 'MOTHERSONSUMI INFOTECH & DESIGNS LIMITED', 'Sydata Consulting India Pvt Ltd', 'Kreate Energy', 'BOLD Technology Systems']\n"
     ]
    }
   ],
   "source": [
    "# extract the company name text iteratively from these tags one by one\n",
    "\n",
    "for i in company_tag:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "company_name = company_name[0:10]\n",
    "print(\"LIST top 10 job data's : \\n\", company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35d6497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"17c5a314-ebbe-45f5-a95d-4da58114b4ba\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"7292670c-5b54-4679-8ebc-d67239158d91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"8b6b71fb-b685-4f26-8aa2-0bad5e75c5a8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"277e3b70-104a-4c73-8844-3640feaa1c92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"e55ab5ef-a44e-41d7-aa4d-244845e4e063\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"de880dee-14c5-445f-bda6-7a7c2668db54\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"55c1fedc-4bc2-4375-866b-ab0189e0077d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"52410795-447d-4bd9-9c21-7dbcb3059ee4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"62a3f226-5b9f-4de0-b7d4-48d4008f834a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"c627b9d389762ca0092b1cdf07a35964\", element=\"0494c749-5301-4dcc-8faf-c61f9f4c45fa\")>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-experience\n",
    "\n",
    "exp_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "exp_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d825250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LIST top 10 job data's job title: \n",
      " ['2-5 ', '4-7 ', '5-10 ', '1-3 ', '2-7 ', '2-7 ', '4-8 ', '3-8 ', '2-4 ', '3-6 ']\n"
     ]
    }
   ],
   "source": [
    "# extract the job experience text iteratively from these tags one by one\n",
    "\n",
    "for i in exp_tag:\n",
    "    experience_required.append(i.text.replace(\"Yrs\",\"\"))\n",
    "experience_required= experience_required[0:10]\n",
    "print(\" LIST top 10 job data's job title: \\n\", experience_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b9df604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...</td>\n",
       "      <td>Sydata Consulting India Pvt Ltd</td>\n",
       "      <td>3-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>Delhi / NCR(Vaishali)</td>\n",
       "      <td>Kreate Energy</td>\n",
       "      <td>2-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0             DigitalBCG GAMMA Data Scientist   \n",
       "1             Senior Associate - Data Science   \n",
       "2            Data Scientist - Noida/Bangalore   \n",
       "3           Data Scientist - Engine Algorithm   \n",
       "4  Data Scientist For Healthcare Product team   \n",
       "5  Data Scientist For Healthcare Product team   \n",
       "6              Data Scientist - MIND Infotech   \n",
       "7                              Data Scientist   \n",
       "8                      Data Science Associate   \n",
       "9                    Knowledge/Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0                     New Delhi, Bangalore/Bengaluru   \n",
       "1  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...   \n",
       "2                         Noida, Bangalore/Bengaluru   \n",
       "3  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "6                                              Noida   \n",
       "7  Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...   \n",
       "8                              Delhi / NCR(Vaishali)   \n",
       "9                                        Delhi / NCR   \n",
       "\n",
       "                               Company_Name Experience  \n",
       "0                   Boston Consulting Group       2-5   \n",
       "1                              Black Turtle       4-7   \n",
       "2                                       EXL      5-10   \n",
       "3                              Primo Hiring       1-3   \n",
       "4                  SECUREKLOUD TECHNOLOGIES       2-7   \n",
       "5                  SECUREKLOUD TECHNOLOGIES       2-7   \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED       4-8   \n",
       "7           Sydata Consulting India Pvt Ltd       3-8   \n",
       "8                             Kreate Energy       2-4   \n",
       "9                   BOLD Technology Systems       3-6   "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making DataFrame of the top 10 job details from the \"wwww.naukri.com\"\n",
    "\n",
    "naukri_filter = pd.DataFrame({'Title':job_title, \n",
    "                       'Location': job_location,\n",
    "                       'Company_Name':company_name, \n",
    "                       'Experience':experience_required,                        \n",
    "                       })\n",
    "naukri_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35afca8",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: 1. Brand 2. Product Description 3. Price\n",
    "To scrape the data you have to go through following steps: 1. Go to Flipkart webpage by url : https://www.flipkart.com/ 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon 3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "\n",
    "After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it. 5. Now scrape data from this page as usual 6. Repeat this until you get data for 100 sunglasses. Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af322dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35763231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “sunglasses” in “search for products, brands and more” field.\n",
    "search_product = driver.find_element(By.XPATH,\"//div[@class='_3OO5Xc']/input\")\n",
    "search_product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a08dae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the search button\n",
    "search_btn = driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b751c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d4429",
   "metadata": {},
   "source": [
    "Scraping the data for the first 100 sunglasses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50180b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating first 3 website pages to scrape the data\n",
    "\n",
    "page_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url=page_url[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eec598d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "Discount=[] \n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    titles_brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in titles_brand:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    titles_Description=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in titles_Description:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    titles_Price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in titles_Price:\n",
    "        Price.append(i.text.replace(\"₹\",\"\"))\n",
    "        \n",
    "    titles_Discount=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']/span\")\n",
    "    for i in titles_Discount:\n",
    "        Discount.append(i.text.replace(\"% off\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "69499a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 100 sunglasses listings on flipkart.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "      <td>749</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>759</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>264</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>249</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>759</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>721</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection, Polarized Round Sunglasses (50)</td>\n",
       "      <td>375</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Round Sunglasses (55)</td>\n",
       "      <td>979</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (60)</td>\n",
       "      <td>385</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product Description Price  \\\n",
       "0   VINCENT CHASE  by Lenskart Polarized, UV Protection Rectangul...   749   \n",
       "1       ROYAL SON   Polarized, UV Protection Aviator Sunglasses (57)   759   \n",
       "2        DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...   177   \n",
       "3       New Specs   UV Protection Rectangular Sunglasses (Free Size)   264   \n",
       "4          PIRASO              UV Protection Aviator Sunglasses (54)   249   \n",
       "..            ...                                                ...   ...   \n",
       "95      ROYAL SON   Polarized, UV Protection Aviator Sunglasses (57)   759   \n",
       "96       Fastrack             UV Protection Wayfarer Sunglasses (55)   721   \n",
       "97      Rich Club     UV Protection, Polarized Round Sunglasses (50)   375   \n",
       "98       Fastrack                UV Protection Round Sunglasses (55)   979   \n",
       "99          NuVew              UV Protection Cat-eye Sunglasses (60)   385   \n",
       "\n",
       "   Discount %  \n",
       "0          62  \n",
       "1          62  \n",
       "2          82  \n",
       "3          89  \n",
       "4          84  \n",
       "..        ...  \n",
       "95         62  \n",
       "96          9  \n",
       "97         62  \n",
       "98          2  \n",
       "99         73  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 100 sunglasses \n",
    "\n",
    "flipkart=pd.DataFrame({})\n",
    "flipkart['Brand']=brand[0:100]\n",
    "flipkart['Product Description']=Description[0:100]\n",
    "flipkart['Price']=Price[0:100]\n",
    "flipkart['Discount %']=Discount[0:100]\n",
    "\n",
    "print(\"TOP 100 sunglasses listings on flipkart.com:\\n\")\n",
    "flipkart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7644e4d",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker: 1. Brand 2. Product Description 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2a86d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00527036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “sneakers” in “search for products, brands and more” field.\n",
    "search_product = driver.find_element(By.XPATH,\"//div[@class='_3OO5Xc']/input\")\n",
    "search_product.send_keys(\"sneakers\")\n",
    "# click the search button\n",
    "search_btn = driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b03042",
   "metadata": {},
   "source": [
    "SCRAPING THE SPECIFIC URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03b0d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09e14b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating first 3 website pages to scrape the data\n",
    "\n",
    "page_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url=page_url[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a806c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "Discount=[] \n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    titles_brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in titles_brand:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    titles_Description=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in titles_Description:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    titles_Price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in titles_Price:\n",
    "        Price.append(i.text.replace(\"₹\",\"\"))\n",
    "        \n",
    "    titles_Discount=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']/span\")\n",
    "    for i in titles_Discount:\n",
    "        Discount.append(i.text.replace(\"% off\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "39ded69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 sneakers listings on flipkart.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price₹</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>499</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RINDAS</td>\n",
       "      <td>Perfect Stylish Casual Shoes For Girls &amp; Women...</td>\n",
       "      <td>298</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>959</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nilatin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>549</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>CR-1 Sneakers For Men</td>\n",
       "      <td>267</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>oxpeo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>449</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>2,078</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Comfortable &amp; Ultra Light Weight Sneaker Sneak...</td>\n",
       "      <td>399</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>WHITE WALKERS</td>\n",
       "      <td>Stylish Walking Partywear Sneakers Casual Shoe...</td>\n",
       "      <td>509</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Scull Wings</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>385</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product Description Price₹  \\\n",
       "0          Layasa                                   Sneakers For Men    499   \n",
       "1          RINDAS  Perfect Stylish Casual Shoes For Girls & Women...    298   \n",
       "2        Roadster                                   Sneakers For Men    959   \n",
       "3         Nilatin                                   Sneakers For Men    549   \n",
       "4        HOTSTYLE                              CR-1 Sneakers For Men    267   \n",
       "..            ...                                                ...    ...   \n",
       "95          oxpeo                                   Sneakers For Men    449   \n",
       "96           PUMA                                   Sneakers For Men  2,078   \n",
       "97       Magnolia  Comfortable & Ultra Light Weight Sneaker Sneak...    399   \n",
       "98  WHITE WALKERS  Stylish Walking Partywear Sneakers Casual Shoe...    509   \n",
       "99    Scull Wings                                   Sneakers For Men    385   \n",
       "\n",
       "   Discount %  \n",
       "0          50  \n",
       "1          70  \n",
       "2          69  \n",
       "3          45  \n",
       "4          46  \n",
       "..        ...  \n",
       "95         71  \n",
       "96         37  \n",
       "97         60  \n",
       "98         57  \n",
       "99         74  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 100 sneakers:\n",
    "\n",
    "flipkart=pd.DataFrame({})\n",
    "flipkart['Brand']=brand[0:100]\n",
    "flipkart['Product Description']=Description[0:100]\n",
    "flipkart['Price₹']=Price[0:100]\n",
    "flipkart['Discount %']=Discount[0:100]\n",
    "\n",
    "print(\"Top 100 sneakers listings on flipkart.com:\\n\")\n",
    "flipkart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6bd830",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes https://www.myntra.com/shoes Set Price filter , Color filter to “Black” And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe .\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there should not be any manual step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1475c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0527a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the Price filter to “Rs. 7149 to Rs. 14099” by checking the respective boxe\n",
    "\n",
    "price = driver.find_elements(By.XPATH,\"//ul[@class ='price-list']//label[@class ='common-customCheckbox vertical-filters-label']/div[@class = 'common-checkboxIndicator']\") \n",
    "price[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d8bbce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the Color filter to “Black”  by checking the box\n",
    "\n",
    "color = driver.find_elements(By.XPATH,\"//li[@class ='colour-listItem']//label[@class ='common-customCheckbox']/div[@class = 'common-checkboxIndicator']\") \n",
    "color[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b2909e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&rf=Price%3A7149.0_14099.0_7149.0%20TO%2014099.0&p=3\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "294e9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating first 3 website pages to scrape the data\n",
    "\n",
    "page_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,\"//li[@class='pagination-number']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url=page_url[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b77f5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    titles_brand=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "    for i in titles_brand:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    titles_Description=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "    for i in titles_Description:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    titles_Price=driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    "    for i in titles_Price:\n",
    "        Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d0276fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 sneakers listings on myntra.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>Rs. 11196Rs. 13995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7999Rs. 15999(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD 15 Basketball Shoes</td>\n",
       "      <td>Rs. 11895Rs. 13995(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>Rs. 7871Rs. 10495(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Black Leather Loafers</td>\n",
       "      <td>Rs. 8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Mules</td>\n",
       "      <td>Rs. 8455Rs. 8900(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                Shoe Description                        Price\n",
       "0        ALDO             Men Leather Loafers   Rs. 7799Rs. 12999(40% OFF)\n",
       "1        Nike    Men React Infinity 3 Running  Rs. 11196Rs. 13995(20% OFF)\n",
       "2        ALDO             Men Leather Loafers   Rs. 7999Rs. 15999(50% OFF)\n",
       "3        Nike      Men KD 15 Basketball Shoes  Rs. 11895Rs. 13995(15% OFF)\n",
       "4        Nike  Women React MR 3 Running Shoes   Rs. 7871Rs. 10495(25% OFF)\n",
       "..        ...                             ...                          ...\n",
       "95       Xtep               Men Running Shoes                     Rs. 7699\n",
       "96  J.FONTINI      Men Leather Formal Loafers                     Rs. 7490\n",
       "97  J.FONTINI       Men Black Leather Loafers                     Rs. 8490\n",
       "98    Saint G      Women Leather Heeled Mules     Rs. 8455Rs. 8900(5% OFF)\n",
       "99  J.FONTINI      Men Leather Formal Loafers                     Rs. 7490\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 100 sneakers listings on myntra.com:\n",
    "\n",
    "myntra =pd.DataFrame({})\n",
    "myntra['Brand']=brand[0:100]\n",
    "myntra['Shoe Description']=Description[0:100]\n",
    "myntra['Price']=Price[0:100]\n",
    "\n",
    "print(\"Top 100 sneakers listings on myntra.com:\\n\")\n",
    "myntra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "10afdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcdf72",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "909c97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9eeda052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “laptop” in the search field.\n",
    "search_product = driver.find_element(By.XPATH,\"//div[@class='nav-search-field ']/input\")\n",
    "search_product.send_keys(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "774db6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the search button\n",
    "search_btn = driver.find_element(By.XPATH,\"//div[@class='nav-search-submit nav-sprite']\")\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0ee58571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying CPU Type filter to “Intel Core i7” filter by checking the respective box\n",
    "i7_clk=driver.find_elements(By.XPATH,\"//span[@class='a-size-base a-color-base']\")\n",
    "for i in i7_clk:\n",
    "    if i.text == 'Intel Core i7':   \n",
    "        i.click() # Checking the checkbox to apply filter on the laptop\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eb7092ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "Title=[]\n",
    "Rating=[]\n",
    "Price=[]\n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "titles=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i in titles:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "titles_rat=driver.find_elements(By.XPATH,\"//div[@class='a-row a-size-small']/span\")\n",
    "for i in titles_rat:\n",
    "    Rating.append(i.get_attribute(\"aria-label\"))\n",
    "        \n",
    "titles_Price=driver.find_elements(By.XPATH,\"//span[@class='a-price']\")\n",
    "for i in titles_Price:\n",
    "    Price.append(i.text[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8f56ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extratcing ratings from the unorganised rating tag\n",
    "\n",
    "rating=[]\n",
    "for i in range(0,len(Rating)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        rating.append(Rating[i][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b2590166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for the first 10 laptops data on amazon.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>57,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>75,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1,08,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Lenovo IdeaPad Slim 3i (82H801CSIN) ...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>38,325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 Intel Core i7 6t...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>39,177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 7th Gen 14.Inch(3...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>51,995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...    4.3    89,990\n",
       "1  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    4.2    57,600\n",
       "2  Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...    3.8    75,990\n",
       "3  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...    3.9    82,990\n",
       "4  Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...    4.3  1,08,990\n",
       "5  Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...    4.0    87,900\n",
       "6  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...    3.8    86,990\n",
       "7  (Renewed) Lenovo IdeaPad Slim 3i (82H801CSIN) ...    3.8    38,325\n",
       "8  (Renewed) Dell Latitude E7470 Intel Core i7 6t...    3.8    39,177\n",
       "9  (Renewed) Dell Intel Core i7 7th Gen 14.Inch(3...    3.4    51,995"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 10 laptops data on amazon.com:\n",
    "\n",
    "amazon =pd.DataFrame({})\n",
    "amazon['Title']=Title[0:10]\n",
    "amazon['Rating']=rating[0:10]\n",
    "amazon['Price']=Price[0:10]\n",
    "\n",
    "print(\"The data for the first 10 laptops data on amazon.com:\\n\")\n",
    "amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e7f90",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.ambitionbox.com/\n",
    "1. Click on the Job option\n",
    "2. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "3. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "4. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "5. Finally create a dataframe of the scraped data. Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a5006f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\" https://www.ambitionbox.com//\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6ccbd01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the \"Jobs\" webpage\n",
    "cl_job = driver.find_element(By.XPATH,\"//a[@class='link jobs']\")\n",
    "cl_job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "12fb84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In place of “Search by Designations, Companies, Skills” enter “Data Scientist” \n",
    "\n",
    "search_title = driver.find_element(By.XPATH,\"//span[@class='twitter-typeahead']/input\")\n",
    "search_title.send_keys(\"Data Scientist\")\n",
    "\n",
    "#click on search button.\n",
    "search_btn = driver.find_element(By.XPATH,\"//button[@class='ab_btn search-btn round']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c66bdcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_loc = driver.find_element(By.XPATH,\"//div[@class='show-flex']/div[2]\") # Location dropdown\n",
    "cl_loc.click()    \n",
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "873443b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "aa59bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name, No. of days ago when job was posted, Rating of the company\n",
    "\n",
    "#creating empty list\n",
    "company_name = []\n",
    "job_posted = []\n",
    "rating = []\n",
    "\n",
    "#Scraing all tags\n",
    "\n",
    "company=driver.find_elements(By.XPATH,\"//div[@class='company-info']\")\n",
    "for i in company:\n",
    "    company_name.append(i.text.split(\"\\n\")[0])\n",
    "    rating.append(i.text.split(\"\\n\")[1])\n",
    "    \n",
    "posted=driver.find_elements(By.XPATH,\"//span[@class='body-small-l']\")\n",
    "for i in posted:\n",
    "    job_posted.append(i.text)\n",
    "    \n",
    "# extratcing job posted days from the unorganised job posted tag\n",
    "\n",
    "posted=[]\n",
    "for i in range(0,len(job_posted)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        posted.append(job_posted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "092277a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for the first 10 jobs results in ambitionbox.com :\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job_Posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latent bridge</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InfoEdge India Ltd.</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Careerera</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRMnext</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Careernet Consulting</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company_name Job_Posted Rating\n",
       "0  Optum Global Solutions (India) Private Limited    11d ago    4.1\n",
       "1                   GENPACT India Private Limited    18d ago    4.0\n",
       "2                                   Latent bridge     2d ago    4.5\n",
       "3                         Dew Solutions Pvt. Ltd.     9d ago    4.3\n",
       "4                             InfoEdge India Ltd.    16d ago    3.9\n",
       "5                         Info Edge India Limited    17d ago    3.9\n",
       "6                         Info Edge India Limited    17d ago    3.9\n",
       "7                                       Careerera     4d ago    3.8\n",
       "8                                         CRMnext    12d ago    4.1\n",
       "9                            Careernet Consulting   1mon ago    3.9"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe \n",
    "\n",
    "ambition = pd.DataFrame({})\n",
    "ambition[\"Company_name\"] = company_name[1:]\n",
    "ambition[\"Job_Posted\"] = posted\n",
    "ambition[\"Rating\"] = rating[1:]\n",
    "\n",
    "print(\"The data for the first 10 jobs results in ambitionbox.com :\\n \")\n",
    "ambition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9617f3",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "25b3422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\" https://www.ambitionbox.com//\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "74dceee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on Salary webpage\n",
    "driver.find_element(By.XPATH,\"//a[@class='link salaries']\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "91672c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "search_job = driver.find_element(By.ID,\"jobProfileSearchbox\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "clk=driver.find_elements(By.XPATH,\"//div[@class='suggestion_wrap tt-suggestion tt-selectable']\")\n",
    "for i in clk:\n",
    "    if i.text == 'Data Scientist':   \n",
    "        i.click() # click on “Data Scientist”\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ad91669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape Company name, Number of salaries, Average salary, Min salary, Max Salary, experience required.\n",
    "\n",
    "company_name = []\n",
    "salary_record = []\n",
    "average_salary = []\n",
    "min_salary = []\n",
    "max_salary = []\n",
    "exp = []\n",
    "\n",
    "#Scraing all tags\n",
    "\n",
    "company=driver.find_elements(By.XPATH,\"//div[@class='company-info']\")\n",
    "for i in company:\n",
    "    company_name.append(i.text.split(\"\\n\")[0])                              #company name\n",
    "    salary_record.append(i.text.replace(\"based on\", \" \").replace(\"salaries\",\"\").split(\"\\n\")[1:2]) #Total Salary Record\n",
    "    exp.append(i.text.replace(\"yrs exp\",\"\").replace(\"yr exp\",\"\").split(\"\\n\")[-1])                # Experience required\n",
    "    \n",
    "avg_salary=driver.find_elements(By.XPATH,\"//div[@class='average-indicator-wrapper']\")\n",
    "for i in avg_salary:\n",
    "    average_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\"))            # average salary\n",
    "\n",
    "salary=driver.find_elements(By.XPATH,\"//div[@class='salary-values']\")\n",
    "for i in salary:\n",
    "    min_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\").split(\"\\n\")[0])  # minimum salary\n",
    "    max_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\").split(\"\\n\")[1])  # maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0f16fe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " first 10 Companies results in ambitionbox.com :\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Total_Salary_Record</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Average_Salary_L</th>\n",
       "      <th>Minimum_Salary_L</th>\n",
       "      <th>Maximum_Salary_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-3 erience (based on 35 salaries)</td>\n",
       "      <td>31.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 274 salaries)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>2 erience (based on 18 salaries)</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tekion</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>2-4 erience (based on 35 salaries)</td>\n",
       "      <td>21.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 122 salaries)</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>2-4 erience (based on 60 salaries)</td>\n",
       "      <td>20.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 64 salaries)</td>\n",
       "      <td>20.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-4 erience (based on 87 salaries)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1-2 erience (based on 29 salaries)</td>\n",
       "      <td>19.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Myntra</td>\n",
       "      <td>[Software Engineer Salary]</td>\n",
       "      <td>1 erience (based on 10 salaries)</td>\n",
       "      <td>19.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name         Total_Salary_Record  \\\n",
       "0                                 Google  [Software Engineer Salary]   \n",
       "1                  Microsoft Corporation  [Software Engineer Salary]   \n",
       "2                          Goldman Sachs  [Software Engineer Salary]   \n",
       "3                                 Tekion  [Software Engineer Salary]   \n",
       "4                                 Amazon  [Software Engineer Salary]   \n",
       "5  Servicenow Software Development India  [Software Engineer Salary]   \n",
       "6                               Flipkart  [Software Engineer Salary]   \n",
       "7                                Walmart  [Software Engineer Salary]   \n",
       "8                                 PayPal  [Software Engineer Salary]   \n",
       "9                                 Myntra  [Software Engineer Salary]   \n",
       "\n",
       "                   Experience_Required Average_Salary_L Minimum_Salary_L  \\\n",
       "0   1-3 erience (based on 35 salaries)             31.3             11.0   \n",
       "1  1-4 erience (based on 274 salaries)             24.0             13.0   \n",
       "2     2 erience (based on 18 salaries)             23.0             12.0   \n",
       "3   2-4 erience (based on 35 salaries)             21.2             12.0   \n",
       "4  1-4 erience (based on 122 salaries)             21.0              8.0   \n",
       "5   2-4 erience (based on 60 salaries)             20.5             13.0   \n",
       "6   1-4 erience (based on 64 salaries)             20.4              7.5   \n",
       "7   1-4 erience (based on 87 salaries)             20.0             11.4   \n",
       "8   1-2 erience (based on 29 salaries)             19.9             11.0   \n",
       "9     1 erience (based on 10 salaries)             19.5             14.0   \n",
       "\n",
       "  Maximum_Salary_L  \n",
       "0             65.0  \n",
       "1             50.0  \n",
       "2             34.0  \n",
       "3             33.0  \n",
       "4             45.0  \n",
       "5             28.0  \n",
       "6             31.0  \n",
       "7             32.5  \n",
       "8             31.0  \n",
       "9             27.0  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe for the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "\n",
    "ambition =pd.DataFrame({})\n",
    "ambition[\"Company_Name\"] = company_name[:10]\n",
    "ambition[\"Total_Salary_Record\"] = salary_record[:10]\n",
    "ambition[\"Experience_Required\"] = exp[:10]\n",
    "ambition[\"Average_Salary_L\"] = average_salary[:10]\n",
    "ambition[\"Minimum_Salary_L\"] = min_salary\n",
    "ambition[\"Maximum_Salary_L\"] = max_salary\n",
    "\n",
    "print(\" first 10 Companies results in ambitionbox.com :\\n \")\n",
    "ambition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "acd5058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5289ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
